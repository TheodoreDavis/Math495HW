{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 4 is due on Tuesday 10/27 at 11:59 pm CST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use carprice data from here https://www.kaggle.com/hellbuoy/car-price-prediction in this homework for problem 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1   [50]\n",
    "After doing preliminary analysis on the data, divide the data to testing and training set. Create a multiple regression model using price as a dependent variable. You decide which numerical variables you want to use. You can start with all the numerical variables and tune the model to make the model better. You want to use as many variables as you can that are significant with the p-value of 0.1 or less. You will have to report the summary of the model, predictions and actual values as two columns in a dataframe, and $R^2$ value of for the training and testing data set. Your points in this problem will be based on the performance of your model on the test data. There is no set value of $R^2$ that you need to get. You try to optimize $R^2$ by fine-tuning the model, may be using various combination of testing and training data set. For example, testing can vary from 30% to 20 % and it gives you many models and many $R^2$ values. You can use other techniques that you can think of to improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2   [50]\n",
    "You will use the diabetic data for this problem. The outcome variable, which has $1$s and $0$s, is the dependent variable. Use a part of the data as a training set to create and tune a logistic regression model. You can use the same technique you used in problem 1 for dividing the data to testing and training. Report the model's summary, confusion matrices of the training and testing data set, and the model accuracies for training and testing. Note that prediction from the logistic regression model are probabilities. You can use the round function to turn anything less or equal to $0.5$ to be $0$ and anything more than $0.5$ to be $1$ so that you can compare the prediction and the actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3    [Bonus, optional, 10 ]\n",
    "There are a few variables in the caprice data set that are categorical and ordinal. We can use such variables in regression after changing these to more variables with the values of $1$s and $0$s depending on how many labels the variables have. Such a technique is called $\\textbf{One Hot Encoding}$. Use one-hot encoding and improve the model in problem 1. Any improvement in the accuracy of a model in problem 1 with the test data gets you 10 points."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
